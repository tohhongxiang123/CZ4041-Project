{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Desktop\\Programming\\CZ4041-Project\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.v2 as T\n",
    "from torchvision.io import read_image\n",
    "import timm\n",
    "from timm import create_model\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import LightningDataModule\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "TRAIN_DIR = \"data/train\"\n",
    "TEST_DIR = \"data/test\"\n",
    "OUTPUT_DIR = \"output\"\n",
    "MODEL_CHECKPOINT_PATH = \"output/model_checkpoints/best_loss.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "columns = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n",
    "\n",
    "class PetFinderDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, image_size=224):\n",
    "        self.image_ids = df[\"Id\"].values\n",
    "        self.features = df[columns].values\n",
    "        self.labels = None\n",
    "\n",
    "        if \"Pawpularity\" in df.keys():\n",
    "            self.labels = df[\"Pawpularity\"].values\n",
    "\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = T.Resize([image_size, image_size], antialias=True)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.features[idx]\n",
    "\n",
    "        image_id = self.image_ids[idx]\n",
    "        image = read_image(os.path.join(self.image_dir, image_id + '.jpg'))\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            label = self.labels[idx]\n",
    "            return image_id, features, image, label\n",
    "        \n",
    "        return image_id, features, image\n",
    "\n",
    "# Data Module\n",
    "class PetFinderDataModule(LightningDataModule):\n",
    "    def __init__(self, df_train=None, df_val=None, df_test=None, train_dir=None, val_dir=None, test_dir=None, batch_size=64, image_size=224):\n",
    "        super().__init__()\n",
    "        self.df_train = df_train\n",
    "        self.df_val = df_val\n",
    "        self.df_test = df_test\n",
    "\n",
    "        self.train_dir = train_dir\n",
    "        self.val_dir = val_dir\n",
    "        self.test_dir = test_dir\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(PetFinderDataset(self.df_train, self.train_dir, self.image_size), batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(PetFinderDataset(self.df_val, self.val_dir, self.image_size), batch_size=self.batch_size, shuffle=False)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(PetFinderDataset(self.df_test, self.test_dir, self.image_size), batch_size=self.batch_size, shuffle=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentations\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n",
    "\n",
    "train_transforms = T.Compose(\n",
    "    [\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.RandomVerticalFlip(),\n",
    "        T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "        T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "        T.ToDtype(torch.float32),\n",
    "        T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transforms = T.Compose(\n",
    "    [\n",
    "        T.ConvertImageDtype(torch.float),\n",
    "        T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# https://arxiv.org/abs/1710.09412v2\n",
    "def mixup(x: torch.Tensor, y: torch.Tensor, alpha: float = 1.0):\n",
    "    assert alpha > 0, \"alpha should be larger than 0\"\n",
    "    assert x.size(0) > 1, \"Mixup cannot be applied to a single instance.\"\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    rand_index = torch.randperm(x.size()[0])\n",
    "    mixed_x = lam * x + (1 - lam) * x[rand_index, :]\n",
    "    target_a, target_b = y, y[rand_index]\n",
    "    return mixed_x, target_a, target_b, lam\n",
    "\n",
    "class PawpularityModel(pl.LightningModule):\n",
    "    def __init__(self, model_name=\"swin_large_patch4_window7_224\", pretrained=True):\n",
    "        super().__init__()\n",
    "        self.validation_step_outputs = []\n",
    "        self.training_step_outputs = []\n",
    "\n",
    "        self.backbone = create_model(model_name, pretrained=pretrained, num_classes=0, in_chans=3).to('cuda')\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        num_features = self.backbone.num_features\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(num_features + len(columns), int(num_features / 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(int(num_features / 2), int(num_features / 4)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(int(num_features / 4), 1)\n",
    "        )\n",
    "        \n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.train_transforms = train_transforms\n",
    "        self.test_transforms = test_transforms\n",
    "        \n",
    "    def forward(self, input, features):\n",
    "        x = self.backbone(input)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.cat([x, features], dim=1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def step(self, batch, mode):\n",
    "        image_ids, features, images, labels = batch\n",
    "        labels = labels.float() / 100.0\n",
    "\n",
    "        images = self.train_transforms(images) if mode == \"train\" else self.test_transforms(images)\n",
    "        logits = self.forward(images, features).squeeze(1)\n",
    "        loss = self.criterion(logits, labels)\n",
    "\n",
    "        predictions = logits.sigmoid().detach().cpu() * 100\n",
    "        labels = labels.detach().cpu() * 100\n",
    "\n",
    "        self.log(f'{mode}_loss', loss)\n",
    "        \n",
    "        return loss, predictions, labels\n",
    "\n",
    "    def training_step(self, batch, batch_indexes):\n",
    "        loss, predictions, labels = self.step(batch, 'train')\n",
    "        self.training_step_outputs.append(loss)\n",
    "        return { 'loss': loss, 'predictions': predictions, 'labels': labels }\n",
    "\n",
    "    def validation_step(self, batch, batch_indexes):\n",
    "        loss, predictions, labels = self.step(batch, 'val')\n",
    "        self.validation_step_outputs.append(loss)\n",
    "        return { 'loss': loss, 'predictions': predictions, 'labels': labels }\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        print(f\"Training loss: {torch.stack(self.training_step_outputs).mean()}\")\n",
    "        self.training_step_outputs.clear()\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        print(f\"Validation loss: {torch.stack(self.validation_step_outputs).mean()}\")\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = 20, eta_min=1e-4)\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PawpularityModel()\n",
    "model.to(\"cuda\")\n",
    "checkpoint = torch.load(MODEL_CHECKPOINT_PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "df_test = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\n",
    "df_test = pd.concat([df_test] * 100)\n",
    "df_test = df_test[:100]\n",
    "test_dataloader = PetFinderDataModule(df_test=df_test, test_dir=TEST_DIR, batch_size=8).test_dataloader()\n",
    "\n",
    "final_image_ids = []\n",
    "final_predictions = []\n",
    "for batch, (image_ids, features, images) in enumerate(test_dataloader):\n",
    "    with torch.no_grad():\n",
    "        predictions =  model(torch.as_tensor(images, dtype=torch.float32).cuda(), features.cuda())\n",
    "        predictions = predictions.sigmoid() * 100\n",
    "        predictions = predictions.cpu().data.numpy().reshape(-1)\n",
    "    \n",
    "    final_image_ids += list(image_ids)\n",
    "    final_predictions += list(predictions)\n",
    "\n",
    "df_submission = pd.DataFrame({ \"Id\": final_image_ids, \"Pawpularity\": final_predictions })\n",
    "df_submission.to_csv(os.path.join(OUTPUT_DIR, 'submission.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>38.945671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>38.983631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e429cead1848a298432a0acad014c9d</td>\n",
       "      <td>36.041359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80bc3ccafcc51b66303c2c263aa38486</td>\n",
       "      <td>37.130951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8f49844c382931444e68dffbe20228f4</td>\n",
       "      <td>34.928699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Pawpularity\n",
       "0  4128bae22183829d2b5fea10effdb0c3    38.945671\n",
       "1  43a2262d7738e3d420d453815151079e    38.983631\n",
       "2  4e429cead1848a298432a0acad014c9d    36.041359\n",
       "3  80bc3ccafcc51b66303c2c263aa38486    37.130951\n",
       "4  8f49844c382931444e68dffbe20228f4    34.928699"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
