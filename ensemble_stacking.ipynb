{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.v2 as T\n",
    "from torchvision.io import read_image\n",
    "import timm\n",
    "from timm import create_model\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import LightningDataModule\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "from data_loaders import PetFinderDataModule, columns\n",
    "from transforms import train_transforms, test_transforms, mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=999\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df['normalised_score'] = df['Pawpularity'] / 100\n",
    "\n",
    "# Sturges rule https://www.statology.org/sturges-rule/\n",
    "# We use the bins split our data based on Pawpularity into multiple bins, to perform StratifiedKFold later\n",
    "n_bins = int(np.ceil(1 + (np.log2(len(df)))))\n",
    "df['bins'] = pd.cut(df['normalised_score'], bins=n_bins, labels=False)\n",
    "\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "df['fold'] = -1\n",
    "for fold_index, (_, train_index) in enumerate(skf.split(df.index, df['bins'])):\n",
    "    df.iloc[train_index, -1] = fold_index\n",
    "\n",
    "df['fold'] = df['fold'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PawpularityModel(pl.LightningModule):\n",
    "    def __init__(self, model_name=\"swin_large_patch4_window7_224\", pretrained=True):\n",
    "        super().__init__()\n",
    "        self.validation_step_outputs = []\n",
    "        self.training_step_outputs = []\n",
    "\n",
    "        self.backbone = create_model(model_name, pretrained=pretrained, num_classes=0, in_chans=3).to('cuda')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        num_features = self.backbone.num_features\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(num_features + len(columns), 1)\n",
    "        )\n",
    "        \n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def forward(self, input, features):\n",
    "        x = self.backbone(input)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.cat([x, features], dim=1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_indexes):\n",
    "        loss, predictions, labels, rmse = self.step(batch, 'train')\n",
    "        self.training_step_outputs.append({ \"rmse\": rmse, \"loss\": loss })\n",
    "\n",
    "        return { 'loss': loss, 'predictions': predictions, 'labels': labels }\n",
    "\n",
    "    def validation_step(self, batch, batch_indexes):\n",
    "        loss, predictions, labels, rmse = self.step(batch, 'val')\n",
    "        self.validation_step_outputs.append({ \"rmse\": rmse, \"loss\": loss })\n",
    "        \n",
    "        return { 'loss': loss, 'predictions': predictions, 'labels': labels }\n",
    "    \n",
    "    def step(self, batch, mode):\n",
    "        image_ids, features, images, labels = batch\n",
    "        labels = labels.float() / 100.0\n",
    "\n",
    "        images = train_transforms(images) if mode == \"train\" else test_transforms(images)\n",
    "\n",
    "        if torch.rand(1)[0] < 0.5 and mode == 'train' and len(images) > 1:\n",
    "            mix_images, target_a, target_b, lam = mixup(images, labels, alpha=1.0)\n",
    "            logits = self.forward(mix_images, features).squeeze(1)\n",
    "            loss = self.criterion(logits, target_a) * lam + (1 - lam) * self.criterion(logits, target_b)\n",
    "        else:\n",
    "            logits = self.forward(images, features).squeeze(1)\n",
    "            loss = self.criterion(logits, labels)\n",
    "\n",
    "        predictions = logits.sigmoid().detach().cpu() * 100\n",
    "        labels = labels.detach().cpu() * 100\n",
    "        \n",
    "        rmse = mean_squared_error(predictions, labels, squared=False) # loss uses BCELoss, while we still calculate RMSE to check\n",
    "        rmse = torch.tensor(rmse, dtype=torch.float32)\n",
    "\n",
    "        self.log(f'{mode}_loss', loss)\n",
    "        \n",
    "        return loss, predictions, labels, rmse\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        rsmes = [x[\"rmse\"] for x in self.training_step_outputs]\n",
    "        rsme = torch.stack(rsmes).mean()\n",
    "\n",
    "        self.log(f'train_rmse', rsme, prog_bar=True)\n",
    "\n",
    "        self.training_step_outputs.clear()\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        rsmes = [x[\"rmse\"] for x in self.validation_step_outputs]\n",
    "        rsme = torch.stack(rsmes).mean()\n",
    "\n",
    "        self.log(f'val_rmse', rsme, prog_bar=True)\n",
    "        \n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-5)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = 20, eta_min=1e-4)\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
