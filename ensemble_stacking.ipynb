{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\q\\Desktop\\Programming\\ML\\venv\\Lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\Users\\q\\Desktop\\Programming\\ML\\venv\\Lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\Users\\q\\Desktop\\Programming\\ML\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\q\\Desktop\\Programming\\ML\\venv\\Lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.v2 as T\n",
    "from torchvision.io import read_image\n",
    "import timm\n",
    "from timm import create_model\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import LightningDataModule\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "from data_loaders import PetFinderDataModule, columns\n",
    "from transforms import train_transforms, test_transforms, mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=999\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms = True\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "TRAIN_DIR = \"data/train\"\n",
    "TEST_DIR = \"data/test\"\n",
    "OUTPUT_DIR = \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df['normalised_score'] = df['Pawpularity'] / 100\n",
    "\n",
    "# Sturges rule https://www.statology.org/sturges-rule/\n",
    "# We use the bins split our data based on Pawpularity into multiple bins, to perform StratifiedKFold later\n",
    "n_bins = int(np.ceil(1 + (np.log2(len(df)))))\n",
    "df['bins'] = pd.cut(df['normalised_score'], bins=n_bins, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 50\n",
    "oof_predictions = { \"ids\": [], \"predictions\": [], \"target\": [], \"fold\": [] }\n",
    "\n",
    "class PawpularityModel(pl.LightningModule):\n",
    "    def __init__(self, model_name=\"swin_large_patch4_window7_224\", pretrained=True):\n",
    "        super().__init__()\n",
    "        self.validation_step_outputs = []\n",
    "        self.training_step_outputs = []\n",
    "\n",
    "        self.fold = 1\n",
    "\n",
    "        self.backbone = create_model(model_name, pretrained=pretrained, num_classes=NUM_CLASSES, in_chans=3).to('cuda')\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def forward(self, input, features):\n",
    "        x = self.backbone(input)\n",
    "\n",
    "        x = torch.cat([x, features], dim=1)\n",
    "        x = torch.sigmoid(x).sum(1) / (NUM_CLASSES + len(features))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_indexes):\n",
    "        loss, predictions, labels, rmse = self.step(batch, 'train')\n",
    "        self.training_step_outputs.append({ \"rmse\": rmse, \"loss\": loss })\n",
    "\n",
    "        return { 'loss': loss, 'predictions': predictions, 'labels': labels }\n",
    "\n",
    "    def validation_step(self, batch, batch_indexes):\n",
    "        loss, predictions, labels, rmse = self.step(batch, 'val')\n",
    "        self.validation_step_outputs.append({ \"rmse\": rmse, \"loss\": loss })\n",
    "\n",
    "        image_ids, _, _, _ = batch\n",
    "        oof_predictions[\"ids\"].append(image_ids)\n",
    "        oof_predictions[\"predictions\"].append(predictions.detach().numpy())\n",
    "        oof_predictions[\"target\"].append(labels.detach().numpy())\n",
    "        oof_predictions[\"fold\"].append([self.fold] * len(image_ids))\n",
    "        \n",
    "        return { 'loss': loss, 'predictions': predictions, 'labels': labels }\n",
    "    \n",
    "    def step(self, batch, mode):\n",
    "        image_ids, features, images, labels = batch\n",
    "        labels = labels.float() / 100.0\n",
    "\n",
    "        images = train_transforms(images) if mode == \"train\" else test_transforms(images)\n",
    "\n",
    "        if torch.rand(1)[0] < 0.5 and mode == 'train' and len(images) > 1:\n",
    "            mix_images, target_a, target_b, lam = mixup(images, labels, alpha=1.0)\n",
    "            logits = self.forward(mix_images, features).squeeze(-1)\n",
    "            loss = self.criterion(logits, target_a) * lam + (1 - lam) * self.criterion(logits, target_b)\n",
    "        else:\n",
    "            logits = self.forward(images, features).squeeze(-1)\n",
    "            loss = self.criterion(logits, labels)\n",
    "\n",
    "        predictions = logits.detach().cpu() * 100\n",
    "        labels = labels.detach().cpu() * 100\n",
    "        \n",
    "        rmse = mean_squared_error(predictions, labels, squared=False) # loss uses BCELoss, while we still calculate RMSE to check\n",
    "        rmse = torch.tensor(rmse, dtype=torch.float32)\n",
    "\n",
    "        self.log(f'{mode}_loss', loss)\n",
    "        \n",
    "        return loss, predictions, labels, rmse\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        rsmes = [x[\"rmse\"] for x in self.training_step_outputs]\n",
    "        rsme = torch.stack(rsmes).mean()\n",
    "\n",
    "        self.log(f'train_rmse', rsme, prog_bar=True)\n",
    "\n",
    "        self.training_step_outputs.clear()\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        rsmes = [x[\"rmse\"] for x in self.validation_step_outputs]\n",
    "        rsme = torch.stack(rsmes).mean()\n",
    "\n",
    "        self.log(f'val_rmse', rsme, prog_bar=True)\n",
    "        \n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-5)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = 20, eta_min=1e-4)\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\q\\Desktop\\Programming\\ML\\venv\\Lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: output\\logs\\lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type              | Params\n",
      "------------------------------------------------\n",
      "0 | backbone  | SwinTransformer   | 195 M \n",
      "1 | criterion | BCEWithLogitsLoss | 0     \n",
      "------------------------------------------------\n",
      "195 M     Trainable params\n",
      "0         Non-trainable params\n",
      "195 M     Total params\n",
      "780.289   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\q\\Desktop\\Programming\\ML\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\q\\Desktop\\Programming\\ML\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  64%|██████▍   | 633/992 [2:02:14<1:09:19, 11.59s/it, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\q\\Desktop\\Programming\\ML\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:53: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\q\\Desktop\\Programming\\ML\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:   1%|          | 2/248 [00:07<15:10,  3.70s/it]"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "df_test = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\n",
    "for fold_index, (train_index, val_index) in enumerate(skf.split(df.index, df['bins'])):\n",
    "    df_train = df.iloc[train_index]\n",
    "    df_val = df.iloc[val_index]\n",
    "\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_val = df_val.reset_index(drop=True)\n",
    "\n",
    "    data_module = PetFinderDataModule(\n",
    "        df_train=df_train, \n",
    "        df_val=df_val, \n",
    "        df_test=df_test, \n",
    "        train_dir=TRAIN_DIR, \n",
    "        val_dir=TRAIN_DIR, \n",
    "        test_dir=TEST_DIR, \n",
    "        batch_size=8,\n",
    "        image_size=224\n",
    "    )\n",
    "\n",
    "    model_name = \"swin_large_patch4_window7_224\"\n",
    "    model = PawpularityModel(model_name=model_name, pretrained=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor=\"val_loss\")\n",
    "    lr_monitor = callbacks.LearningRateMonitor()\n",
    "    loss_checkpoint = callbacks.ModelCheckpoint(dirpath=os.path.join(OUTPUT_DIR, \"model_checkpoints\"), filename=\"best_loss\", monitor=\"val_loss\", save_top_k=1, mode=\"min\", save_last=False)\n",
    "\n",
    "    logger = TensorBoardLogger(os.path.join(OUTPUT_DIR, \"logs\"))\n",
    "\n",
    "    trainer = pl.Trainer(max_epochs=1, callbacks=[lr_monitor, loss_checkpoint, early_stopping], logger=logger)\n",
    "    trainer.fit(model, datamodule=data_module)\n",
    "    trainer.validate(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0009c66b9439883ba2750fb825e1d7db 59.48245\n",
      "006cda7fec46a527f9f627f4722a2304 59.402954\n",
      "006fe962f5f7e2c5f527b2e27e28ed6d 60.606064\n",
      "0075ec6503412f21cf65ac5f43d80440 58.60515\n",
      "0009c66b9439883ba2750fb825e1d7db 58.964478\n",
      "006cda7fec46a527f9f627f4722a2304 58.74107\n",
      "006fe962f5f7e2c5f527b2e27e28ed6d 60.1452\n",
      "0075ec6503412f21cf65ac5f43d80440 58.093388\n",
      "0009c66b9439883ba2750fb825e1d7db 58.964478\n",
      "006cda7fec46a527f9f627f4722a2304 58.74107\n",
      "006fe962f5f7e2c5f527b2e27e28ed6d 60.1452\n",
      "0075ec6503412f21cf65ac5f43d80440 58.093388\n",
      "0007de18844b0dbbb5e1f607da0606e0 58.884144\n",
      "001dc955e10590d3ca4673f034feeef2 58.32569\n",
      "005017716086b8d5e118dd9fe26459b1 59.138496\n",
      "00655425c10d4c082dd7eeb97fa4fb17 58.69689\n",
      "0007de18844b0dbbb5e1f607da0606e0 58.385883\n",
      "001dc955e10590d3ca4673f034feeef2 57.50579\n",
      "005017716086b8d5e118dd9fe26459b1 58.714615\n",
      "00655425c10d4c082dd7eeb97fa4fb17 57.986305\n",
      "0007de18844b0dbbb5e1f607da0606e0 58.385883\n",
      "001dc955e10590d3ca4673f034feeef2 57.50579\n",
      "005017716086b8d5e118dd9fe26459b1 58.714615\n",
      "00655425c10d4c082dd7eeb97fa4fb17 57.986305\n",
      "001dd4f6fafb890610b1635f967ea081 57.352543\n",
      "0023b8a3abc93c712edd6120867deb53 57.635372\n",
      "0042bc5bada6d1cf8951f8f9f0d399fa 58.9149\n",
      "00630b1262efe301cb15a3b2022ba744 60.02634\n",
      "001dd4f6fafb890610b1635f967ea081 56.91361\n",
      "0023b8a3abc93c712edd6120867deb53 57.1185\n",
      "0042bc5bada6d1cf8951f8f9f0d399fa 58.39802\n",
      "00630b1262efe301cb15a3b2022ba744 59.51518\n",
      "001dd4f6fafb890610b1635f967ea081 56.91361\n",
      "0023b8a3abc93c712edd6120867deb53 57.1185\n",
      "0042bc5bada6d1cf8951f8f9f0d399fa 58.39802\n",
      "00630b1262efe301cb15a3b2022ba744 59.51518\n",
      "0049cb81313c94fa007286e9039af910 58.567947\n",
      "00524dbf2637a80cbc80f70d3ff59616 60.744102\n",
      "006483b96ca9c09b7afed3e3d3af539d 59.077103\n",
      "00768659c1c90409f81dcdecbd270513 57.157238\n",
      "0049cb81313c94fa007286e9039af910 58.181393\n",
      "00524dbf2637a80cbc80f70d3ff59616 60.380627\n",
      "006483b96ca9c09b7afed3e3d3af539d 58.7725\n",
      "00768659c1c90409f81dcdecbd270513 56.671803\n",
      "0049cb81313c94fa007286e9039af910 58.181393\n",
      "00524dbf2637a80cbc80f70d3ff59616 60.380627\n",
      "006483b96ca9c09b7afed3e3d3af539d 58.7725\n",
      "00768659c1c90409f81dcdecbd270513 56.671803\n",
      "0013fd999caf9a3efe1352ca1b0d937e 60.44497\n",
      "0018df346ac9c1d8413cfcc888ca8246 59.05887\n",
      "0031d6a9ef7340f898c3e05f92c7bb04 60.148506\n",
      "0067aaaa500b530c76b9c91af34b4cb8 57.888264\n",
      "0013fd999caf9a3efe1352ca1b0d937e 59.936287\n",
      "0018df346ac9c1d8413cfcc888ca8246 58.46351\n",
      "0031d6a9ef7340f898c3e05f92c7bb04 59.7424\n",
      "0067aaaa500b530c76b9c91af34b4cb8 57.546795\n",
      "0013fd999caf9a3efe1352ca1b0d937e 59.936287\n",
      "0018df346ac9c1d8413cfcc888ca8246 58.46351\n",
      "0031d6a9ef7340f898c3e05f92c7bb04 59.7424\n",
      "0067aaaa500b530c76b9c91af34b4cb8 57.546795\n"
     ]
    }
   ],
   "source": [
    "for ids, predictions in zip(oof_predictions[\"ids\"], oof_predictions[\"predictions\"]):\n",
    "    for batch_ids, batch_predictions in zip(ids, predictions):\n",
    "        print(batch_ids, batch_predictions.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
