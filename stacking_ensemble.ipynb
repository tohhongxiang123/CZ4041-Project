{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import albumentations\n",
    "import cv2\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import LightningDataModule\n",
    "\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2023\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "\n",
    "TRAIN_IMAGES_DIR = os.path.join(DATA_DIR, 'train')\n",
    "TEST_IMAGES_DIR = os.path.join(DATA_DIR, 'test')\n",
    "\n",
    "OUTPUT_DIR = \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(data: pd.DataFrame, num_splits = 5):\n",
    "    data[\"fold\"] = -1\n",
    "    num_bins = int(np.floor(1 + np.log2(len(data)))) # sturge's rule\n",
    "\n",
    "    data.loc[:, \"bins\"] = pd.cut(data[\"Pawpularity\"], bins=num_bins, labels=False)\n",
    "    skf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=SEED)\n",
    "\n",
    "    for fold_index, (train_idx, val_idx) in enumerate(skf.split(X=data, y=data.bins.values)):\n",
    "        data.loc[val_idx, 'fold'] = fold_index\n",
    "\n",
    "    data = data.drop('bins', axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_features = [\n",
    "    'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n",
    "    'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n",
    "]\n",
    "\n",
    "class PetFinderDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, dir: str, augmentations: albumentations.Compose):\n",
    "        self.ids = df[\"Id\"].values\n",
    "        if \"Pawpularity\" in df.keys():\n",
    "            self.targets = df[\"Pawpularity\"].values\n",
    "        else:\n",
    "            self.targets = [-1] * len(df)\n",
    "        self.dense_features = df[dense_features].values\n",
    "\n",
    "        image_paths = [os.path.join(dir, f\"{x}.jpg\") for x in df[\"Id\"].values]\n",
    "        self.image_paths = image_paths\n",
    "\n",
    "        self.augmentations = augmentations\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        image_id = self.ids[item]\n",
    "\n",
    "        image = cv2.imread(self.image_paths[item])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.augmentations is not None:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "            \n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        \n",
    "        features = self.dense_features[item, :]\n",
    "        targets = self.targets[item]\n",
    "        \n",
    "        return image_id, torch.tensor(features, dtype=torch.float), torch.tensor(image, dtype=torch.float), torch.tensor(targets, dtype=torch.float)\n",
    "    \n",
    "class PetFinderDataModule(LightningDataModule):\n",
    "    def __init__(self, \n",
    "                 df_train=None, df_val=None, df_test=None, \n",
    "                 train_images_dir=None, val_images_dir=None, test_images_dir=None, \n",
    "                 train_augmentations=None, val_augmentations=None, test_augmentations=None, \n",
    "                 batch_size=64\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.df_train = df_train\n",
    "        self.df_val = df_val\n",
    "        self.df_test = df_test\n",
    "\n",
    "        self.train_images_dir = train_images_dir\n",
    "        self.val_images_dir = val_images_dir\n",
    "        self.test_images_dir = test_images_dir\n",
    "\n",
    "        self.train_augmentations = train_augmentations\n",
    "        self.val_augmentations = val_augmentations\n",
    "        self.test_augmentations = test_augmentations\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(PetFinderDataset(self.df_train, self.train_images_dir, self.train_augmentations), batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(PetFinderDataset(self.df_val, self.val_images_dir, self.val_augmentations), batch_size=self.batch_size, shuffle=False)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(PetFinderDataset(self.df_test, self.test_images_dir, self.test_augmentations), batch_size=self.batch_size, shuffle=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetPawpularity(pl.LightningModule):\n",
    "    def __init__(self, model_name=\"tf_efficientnet_b0_ns\", pretrained=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = timm.create_model(model_name=model_name, pretrained=pretrained, in_chans=3)\n",
    "        self.backbone.classifier = nn.Linear(self.backbone.classifier.in_features, 128)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out = nn.Linear(128 + 12, 1)\n",
    "\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        self.validation_step_outputs = []\n",
    "        self.training_step_outputs = []\n",
    "\n",
    "    def forward(self, input, features):\n",
    "        x = self.backbone(input)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.cat([x, features], dim=1)\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_indexes):\n",
    "        loss, predictions, labels, rmse = self.step(batch, 'train')\n",
    "        self.training_step_outputs.append({ \"rmse\": rmse, \"loss\": loss })\n",
    "\n",
    "        return { 'loss': loss, 'predictions': predictions, 'labels': labels }\n",
    "\n",
    "    def validation_step(self, batch, batch_indexes):\n",
    "        loss, predictions, labels, rmse = self.step(batch, 'val')\n",
    "        self.validation_step_outputs.append({ \"rmse\": rmse, \"loss\": loss })\n",
    "        \n",
    "        return { 'loss': loss, 'predictions': predictions, 'labels': labels }\n",
    "\n",
    "    def step(self, batch, mode):\n",
    "        image_ids, features, images, labels = batch\n",
    "        labels = labels.float() / 100.0\n",
    "\n",
    "        logits = self.forward(images, features).squeeze(1)\n",
    "        loss = self.criterion(logits, labels) # using BCELoss to optimize models\n",
    "\n",
    "        predictions = logits.sigmoid().detach().cpu() * 100\n",
    "        labels = labels.detach().cpu() * 100\n",
    "        \n",
    "        rmse = mean_squared_error(predictions, labels, squared=False) # keeping track of RMSE as it is the competition metric\n",
    "        rmse = torch.tensor(rmse, dtype=torch.float32)\n",
    "\n",
    "        self.log(f'{mode}_loss', loss)\n",
    "        \n",
    "        return loss, predictions, labels, rmse\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        rsmes = [x[\"rmse\"] for x in self.training_step_outputs]\n",
    "        rsme = torch.stack(rsmes).mean()\n",
    "\n",
    "        self.log(f'train_rmse', rsme, prog_bar=True)\n",
    "\n",
    "        self.training_step_outputs.clear()\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        rsmes = [x[\"rmse\"] for x in self.validation_step_outputs]\n",
    "        rsme = torch.stack(rsmes).mean()\n",
    "\n",
    "        self.log(f'val_rmse', rsme, prog_bar=True)\n",
    "        \n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = 20, eta_min=1e-4)\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinTinyPawpularity(pl.LightningModule):\n",
    "    def __init__(self, model_name=\"swin_tiny_patch4_window7_224\", pretrained=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = timm.create_model(model_name=model_name, pretrained=True, num_classes=128, in_chans=3)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out = nn.Linear(128 + 12, 1)\n",
    "\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        self.validation_step_outputs = []\n",
    "        self.training_step_outputs = []\n",
    "\n",
    "    def forward(self, input, features):\n",
    "        x = self.backbone(input)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.cat([x, features], dim=1)\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_indexes):\n",
    "        loss, predictions, labels, rmse = self.step(batch, 'train')\n",
    "        self.training_step_outputs.append({ \"rmse\": rmse, \"loss\": loss })\n",
    "\n",
    "        return { 'loss': loss, 'predictions': predictions, 'labels': labels }\n",
    "\n",
    "    def validation_step(self, batch, batch_indexes):\n",
    "        loss, predictions, labels, rmse = self.step(batch, 'val')\n",
    "        self.validation_step_outputs.append({ \"rmse\": rmse, \"loss\": loss })\n",
    "        \n",
    "        return { 'loss': loss, 'predictions': predictions, 'labels': labels }\n",
    "\n",
    "    def step(self, batch, mode):\n",
    "        image_ids, features, images, labels = batch\n",
    "        labels = labels.float() / 100.0\n",
    "\n",
    "        logits = self.forward(images, features).squeeze(1)\n",
    "        loss = self.criterion(logits, labels) # using BCELoss to optimize models\n",
    "\n",
    "        predictions = logits.sigmoid().detach().cpu() * 100\n",
    "        labels = labels.detach().cpu() * 100\n",
    "        \n",
    "        rmse = mean_squared_error(predictions, labels, squared=False) # keeping track of RMSE as it is the competition metric\n",
    "        rmse = torch.tensor(rmse, dtype=torch.float32)\n",
    "\n",
    "        self.log(f'{mode}_loss', loss)\n",
    "        \n",
    "        return loss, predictions, labels, rmse\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        rsmes = [x[\"rmse\"] for x in self.training_step_outputs]\n",
    "        rsme = torch.stack(rsmes).mean()\n",
    "\n",
    "        self.log(f'train_rmse', rsme, prog_bar=True)\n",
    "\n",
    "        self.training_step_outputs.clear()\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        rsmes = [x[\"rmse\"] for x in self.validation_step_outputs]\n",
    "        rsme = torch.stack(rsmes).mean()\n",
    "\n",
    "        self.log(f'val_rmse', rsme, prog_bar=True)\n",
    "        \n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = 20, eta_min=1e-4)\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_augmentations(image_size: int):\n",
    "    train_aug = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.SmallestMaxSize(max_size=image_size, p=1),\n",
    "            albumentations.RandomCrop(image_size, image_size, p=1),\n",
    "            albumentations.HueSaturationValue(\n",
    "                hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5\n",
    "            ),\n",
    "            albumentations.RandomBrightnessContrast(\n",
    "                brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5\n",
    "            ),\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "                max_pixel_value=255.0,\n",
    "                p=1.0,\n",
    "            ),\n",
    "        ],\n",
    "        p=1.0,\n",
    "    )\n",
    "\n",
    "    valid_aug = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.SmallestMaxSize(max_size=image_size, p=1),\n",
    "            albumentations.CenterCrop(image_size, image_size, p=1),\n",
    "            albumentations.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "                max_pixel_value=255.0,\n",
    "                p=1.0,\n",
    "            ),\n",
    "        ],\n",
    "        p=1.0,\n",
    "    )\n",
    "\n",
    "    return train_aug, valid_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_and_datamodule(model_name: str, fold_index: int, df_train: pd.DataFrame, df_val: pd.DataFrame):\n",
    "    if model_name == \"swin_tiny_patch4_window7_224\":\n",
    "        image_size = 224\n",
    "        model = SwinTinyPawpularity(pretrained=False)\n",
    "    elif model_name == \"tf_efficientnet_b0_ns_randomcrop\":\n",
    "        image_size = 256\n",
    "        model = EfficientNetPawpularity(pretrained=False)\n",
    "\n",
    "    model.to(\"cuda\")\n",
    "    model_checkpoint_path = os.path.join(OUTPUT_DIR, \"model_checkpoints\", model_name, f\"fold_{fold_index}\", \"best_loss.ckpt\")\n",
    "    checkpoint = torch.load(model_checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    train_aug, valid_aug = create_augmentations(image_size)\n",
    "    data_module = PetFinderDataModule(\n",
    "        df_train=df_train, \n",
    "        df_val=df_val, \n",
    "        train_images_dir=TRAIN_IMAGES_DIR, \n",
    "        val_images_dir=TRAIN_IMAGES_DIR, \n",
    "        train_augmentations=train_aug,\n",
    "        val_augmentations=valid_aug,\n",
    "        batch_size=8\n",
    "    )\n",
    "\n",
    "    return model, data_module\n",
    "\n",
    "def run_predictions(model, data_loader):\n",
    "    final_image_ids = []\n",
    "    final_predictions = []\n",
    "    final_targets = []\n",
    "\n",
    "    for batch, (image_ids, features, images, labels) in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            predictions =  model(torch.as_tensor(images, dtype=torch.float32).cuda(), features.cuda())\n",
    "            predictions = predictions.sigmoid() * 100\n",
    "            predictions = predictions.cpu().data.numpy().reshape(-1)\n",
    "        \n",
    "        final_image_ids += list(image_ids)\n",
    "        final_predictions += list(predictions)\n",
    "        final_targets += list(labels)\n",
    "\n",
    "    return pd.DataFrame({ \"Id\": final_image_ids, \"Predicted\": final_predictions })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\q\\Desktop\\Programming\\ML\\venv\\Lib\\site-packages\\timm\\models\\_factory.py:114: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
      "  model = create_fn(\n",
      "C:\\Users\\q\\AppData\\Local\\Temp\\ipykernel_5608\\2329111599.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_ensemble = pd.concat([df_ensemble, df_val_merged], ignore_index=True)\n",
      "c:\\Users\\q\\Desktop\\Programming\\ML\\venv\\Lib\\site-packages\\timm\\models\\_factory.py:114: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
      "  model = create_fn(\n",
      "c:\\Users\\q\\Desktop\\Programming\\ML\\venv\\Lib\\site-packages\\timm\\models\\_factory.py:114: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
      "  model = create_fn(\n",
      "c:\\Users\\q\\Desktop\\Programming\\ML\\venv\\Lib\\site-packages\\timm\\models\\_factory.py:114: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
      "  model = create_fn(\n",
      "c:\\Users\\q\\Desktop\\Programming\\ML\\venv\\Lib\\site-packages\\timm\\models\\_factory.py:114: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n",
      "  model = create_fn(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
    "num_splits = 5\n",
    "df_5 = create_folds(df, num_splits=num_splits)\n",
    "\n",
    "df_ensemble = pd.DataFrame({ \"Id\": [], \"swin_prediction\": [], \"efficientnet_prediction\": [] })\n",
    "\n",
    "for fold_index in range(num_splits):\n",
    "    df_train = df_5[df_5['fold'] != fold_index].reset_index(drop=True)\n",
    "    df_val = df_5[df_5['fold'] == fold_index].reset_index(drop=True)\n",
    "\n",
    "    swin_model, swin_datamodule = create_model_and_datamodule(\"swin_tiny_patch4_window7_224\", fold_index, df_train, df_val)\n",
    "    efficientnet_model, efficientnet_datamodule = create_model_and_datamodule(\"tf_efficientnet_b0_ns_randomcrop\", fold_index, df_train, df_val)\n",
    "\n",
    "    # run only on out-of-fold predictions\n",
    "    df_val_swin = run_predictions(swin_model, swin_datamodule.val_dataloader())\n",
    "    df_val_swin = df_val_swin.rename(columns={ \"Predicted\": \"swin_prediction\" })\n",
    "    df_val_swin['fold'] = fold_index\n",
    "\n",
    "    df_val_efficientnet = run_predictions(efficientnet_model, efficientnet_datamodule.val_dataloader())\n",
    "    df_val_efficientnet = df_val_efficientnet.rename(columns={ \"Predicted\": \"efficientnet_prediction\" })\n",
    "    df_val_efficientnet['fold'] = fold_index\n",
    "\n",
    "    df_val_merged = pd.merge(df_val_swin, df_val_efficientnet, on=\"Id\")\n",
    "    df_val_merged = pd.merge(df_val_merged, df_val[[\"Id\", \"Pawpularity\", \"fold\"]].rename({ \"Pawpularity\": \"target\" }), on=\"Id\")\n",
    "\n",
    "    df_ensemble = pd.concat([df_ensemble, df_val_merged], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for fold 0: Ensemble: 18.507204988597593, SWIN: 18.753201528243817, EfficientNet: 18.5337780901583\n",
      "RMSE for fold 1: Ensemble: 19.02512879113913, SWIN: 20.093251601368603, EfficientNet: 18.79414931744975\n",
      "RMSE for fold 2: Ensemble: 18.957887315347456, SWIN: 19.5824620417417, EfficientNet: 19.096824362859447\n",
      "RMSE for fold 3: Ensemble: 18.74677806948894, SWIN: 19.225013023193693, EfficientNet: 18.942841446046266\n",
      "RMSE for fold 4: Ensemble: 19.158653100080016, SWIN: 19.230935940263734, EfficientNet: 19.145982931978512\n",
      "Best improvement from using SVM is fold 4: 0.4185716682700473\n"
     ]
    }
   ],
   "source": [
    "best_clf = None\n",
    "best_improvement = float('-inf')\n",
    "best_index = -1\n",
    "\n",
    "for i in range(5):\n",
    "    df_train = df_ensemble[df_ensemble['fold'] != i]\n",
    "    df_val = df_ensemble[df_ensemble['fold'] == i]\n",
    "\n",
    "    X_train = df_train[[\"swin_prediction\", \"efficientnet_prediction\"]].values\n",
    "    y_train = df_train[\"Pawpularity\"].values\n",
    "\n",
    "    X_val = df_val[[\"swin_prediction\", \"efficientnet_prediction\"]].values\n",
    "    y_val = df_val[\"Pawpularity\"].values\n",
    "    \n",
    "    clf = SVR(C=1.0, epsilon=0.2, max_iter=10000)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    predictions = clf.predict(X_val)\n",
    "\n",
    "    rmse = mean_squared_error(predictions, y_val, squared=False)\n",
    "    swin_rmse = mean_squared_error(df_val[\"swin_prediction\"], df_val[\"Pawpularity\"], squared=False)\n",
    "    efficientnet_rmse = mean_squared_error(df_val[\"efficientnet_prediction\"], df_val[\"Pawpularity\"], squared=False)\n",
    "    print(f\"RMSE for fold {i}: Ensemble: {rmse}, SWIN: {swin_rmse}, EfficientNet: {efficientnet_rmse}\")\n",
    "\n",
    "    improvement = (swin_rmse + efficientnet_rmse) / 2 - rmse\n",
    "    if improvement > best_improvement:\n",
    "        best_clf = clf\n",
    "        best_improvement = improvement\n",
    "        best_index = i\n",
    "\n",
    "print(f\"Best improvement from using SVM is fold {i}: {best_improvement}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
