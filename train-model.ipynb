{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import copy\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.io import read_image\n",
    "from timm import create_model\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import callbacks\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import LightningDataModule, LightningModule\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already have 2 directories, `train` and `test`. \n",
    "\n",
    "Let us check the number of test and train instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of training instances: {len(os.listdir('data/train'))}\")\n",
    "print(f\"Number of test instances: {len(os.listdir('data/test'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetFinderDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, image_size=224):\n",
    "        self.X = df[\"Id\"].values\n",
    "        self.y = None\n",
    "\n",
    "        if \"Pawpularity\" in df.keys():\n",
    "            self.y = df[\"Pawpularity\"].values\n",
    "\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = T.Resize([image_size, image_size])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.X[idx]\n",
    "        image = read_image(os.path.join(self.image_dir, image_path + '.jpg'))\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        if self.y is not None:\n",
    "            label = self.y[idx]\n",
    "            return image, label\n",
    "        \n",
    "        return image\n",
    "\n",
    "class PetFinderDataModule(LightningDataModule):\n",
    "    def __init__(self, df_train, df_val):\n",
    "        super().__init__()\n",
    "        self.df_train = df_train\n",
    "        self.df_val = df_val\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(PetFinderDataset(self.df_train, \"data/train\"), batch_size=8, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(PetFinderDataset(self.df_val, \"data/train\"), batch_size=8, shuffle=False) # not recommended to shuffle val/test dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df = df[:50]\n",
    "\n",
    "dataloader = PetFinderDataModule(df, df).val_dataloader()\n",
    "dataiter = iter(dataloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for it, (image, label) in enumerate(zip(images[:16], labels[:16])):\n",
    "    plt.subplot(4, 4, it+1)\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Pawpularity: {int(label)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets define our model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n",
    "\n",
    "train_transforms = T.Compose(\n",
    "    [\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.RandomVerticalFlip(),\n",
    "        T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "        T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "        T.ConvertImageDtype(torch.float),\n",
    "        T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transforms = T.Compose(\n",
    "    [\n",
    "        T.ConvertImageDtype(torch.float),\n",
    "        T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# https://arxiv.org/abs/1710.09412v2\n",
    "def mixup(x: torch.Tensor, y: torch.Tensor, alpha: float = 1.0):\n",
    "    assert alpha > 0, \"alpha should be larger than 0\"\n",
    "    assert x.size(0) > 1, \"Mixup cannot be applied to a single instance.\"\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    rand_index = torch.randperm(x.size()[0])\n",
    "    mixed_x = lam * x + (1 - lam) * x[rand_index, :]\n",
    "    target_a, target_b = y, y[rand_index]\n",
    "    return mixed_x, target_a, target_b, lam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PawpularityModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.validation_step_outputs = []\n",
    "        self.training_step_outputs = []\n",
    "\n",
    "        self.backbone = create_model(\"swin_tiny_patch4_window7_224\", pretrained=True, num_classes=0, in_chans=3)\n",
    "        num_features = self.backbone.num_features\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 1)\n",
    "        )\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.train_transforms = train_transforms\n",
    "        self.test_transforms = test_transforms\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.fc(self.backbone(input))\n",
    "\n",
    "    def step(self, batch, mode):\n",
    "        images, labels = batch\n",
    "        labels = labels.float()\n",
    "        images = self.train_transforms(images) if mode == \"train\" else self.test_transforms(images)\n",
    "\n",
    "        if torch.rand(1)[0] < 0.5 and mode == 'train' and len(images) > 1:\n",
    "            mix_images, target_a, target_b, lam = mixup(images, labels, alpha=0.5)\n",
    "            logits = self.forward(mix_images).squeeze(1)\n",
    "            loss = self.criterion(logits, target_a) * lam + (1 - lam) * self.criterion(logits, target_b)\n",
    "        else:\n",
    "            logits = self.forward(images).squeeze(1)\n",
    "            loss = self.criterion(logits, labels)\n",
    "\n",
    "        predictions = logits.detach().cpu()\n",
    "        labels = labels.detach().cpu()\n",
    "\n",
    "        print(predictions, labels)\n",
    "        self.log(f'{mode}_loss', loss)\n",
    "        \n",
    "        return loss, predictions, labels\n",
    "\n",
    "    def training_step(self, batch, batch_indexes):\n",
    "        loss, predictions, labels = self.step(batch, 'train')\n",
    "        return { 'loss': loss, 'predictions': predictions, 'labels': labels }\n",
    "\n",
    "    def validation_step(self, batch, batch_indexes):\n",
    "        loss, predictions, labels = self.step(batch, 'val')\n",
    "        return { 'loss': loss, 'predictions': predictions, 'labels': labels }\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-5)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = 20, eta_min=1e-4)\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df[\"Id\"], df[\"Pawpularity\"])):\n",
    "    df_train = df.loc[train_idx].reset_index(drop=True)\n",
    "    df_val = df.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    data_module = PetFinderDataModule(df_train, df_val)\n",
    "    model = PawpularityModel()\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor=\"val_loss\")\n",
    "    lr_monitor = callbacks.LearningRateMonitor()\n",
    "    loss_checkpoint = callbacks.ModelCheckpoint(filename=\"best_loss\", monitor=\"val_loss\", save_top_k=1, mode=\"min\", save_last=False)\n",
    "\n",
    "    logger = TensorBoardLogger(\"logs/swin_224\")\n",
    "\n",
    "    trainer = pl.Trainer(max_epochs=10, callbacks=[lr_monitor, loss_checkpoint, early_stopping], logger=logger)\n",
    "    trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "path = glob.glob(f'./lightning_logs/version_0/events*')[0]\n",
    "event_acc = EventAccumulator(path, size_guidance={'scalars': 0})\n",
    "event_acc.Reload()\n",
    "\n",
    "scalars = {}\n",
    "for tag in event_acc.Tags()['scalars']:\n",
    "    events = event_acc.Scalars(tag)\n",
    "    scalars[tag] = [event.value for event in events]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(len(scalars['lr-AdamW'])), scalars['lr-AdamW'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('lr')\n",
    "plt.title('adamw lr')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(len(scalars['train_loss'])), scalars['train_loss'], label='train_loss')\n",
    "plt.plot(range(len(scalars['val_loss'])), scalars['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.ylabel('rmse')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('train/val rmse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 4\n",
    "\n",
    "model = PawpularityModel()\n",
    "checkpoint = torch.load(\"tensorboardlogger/swin_224/lightning_logs/version_0/checkpoints/best_loss.ckpt\")\n",
    "\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "data_module = PetFinderDataModule(df, df)\n",
    "dataiter = iter(data_module.val_dataloader())\n",
    "batch = next(dataiter)\n",
    "images, labels = batch\n",
    "rows = len(images) // cols + 1\n",
    "\n",
    "figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 8))\n",
    "for i in range(len(images)):\n",
    "    image = images[i]\n",
    "    label = labels[i]\n",
    "    with torch.no_grad():\n",
    "        prediction = model(torch.as_tensor(image, dtype=torch.float32, device='cpu').unsqueeze(0))\n",
    "        prediction = prediction.cpu().numpy()[0][0]\n",
    "\n",
    "    ax.ravel()[i].imshow(image.permute(1, 2, 0))\n",
    "    ax.ravel()[i].set_axis_off()\n",
    "    ax.ravel()[i].set_title(f\"{round(prediction)}, Actual: {label}\")\n",
    "\n",
    "plt.tight_layout(pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
